<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>【论文复现】Eyes Tell All_Irregular Pupil Shapes Reveal GAN-generated Faces | Hozenghan的博客</title><meta name="author" content="Hozenghan"><meta name="copyright" content="Hozenghan"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="复现论文：Eyes Tell All_ Irregular Pupil Shapes Reveal GAN-generated Faces的记录">
<meta property="og:type" content="article">
<meta property="og:title" content="【论文复现】Eyes Tell All_Irregular Pupil Shapes Reveal GAN-generated Faces">
<meta property="og:url" content="http://hozenghan.github.io/blog/2025/03/02/paper/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91Eyes%20Tell%20All_Irregular%20Pupil%20Shapes%20Reveal%20GAN-generated%20Faces/index.html">
<meta property="og:site_name" content="Hozenghan的博客">
<meta property="og:description" content="复现论文：Eyes Tell All_ Irregular Pupil Shapes Reveal GAN-generated Faces的记录">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://hozenghan.github.io/blog/coverImages/paper-1.jpg">
<meta property="article:published_time" content="2025-03-01T16:00:00.000Z">
<meta property="article:modified_time" content="2025-03-02T15:44:30.883Z">
<meta property="article:author" content="Hozenghan">
<meta property="article:tag" content="网络安全">
<meta property="article:tag" content="scu">
<meta property="article:tag" content="论文复现">
<meta property="article:tag" content="paper">
<meta property="article:tag" content="GAN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://hozenghan.github.io/blog/coverImages/paper-1.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "【论文复现】Eyes Tell All_Irregular Pupil Shapes Reveal GAN-generated Faces",
  "url": "http://hozenghan.github.io/blog/2025/03/02/paper/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91Eyes%20Tell%20All_Irregular%20Pupil%20Shapes%20Reveal%20GAN-generated%20Faces/",
  "image": "http://hozenghan.github.io/blog/coverImages/paper-1.jpg",
  "datePublished": "2025-03-01T16:00:00.000Z",
  "dateModified": "2025-03-02T15:44:30.883Z",
  "author": [
    {
      "@type": "Person",
      "name": "Hozenghan",
      "url": "http://hozenghan.github.io/blog/"
    }
  ]
}</script><link rel="shortcut icon" href="/blog/images/sun.png"><link rel="canonical" href="http://hozenghan.github.io/blog/2025/03/02/paper/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91Eyes%20Tell%20All_Irregular%20Pupil%20Shapes%20Reveal%20GAN-generated%20Faces/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/blog/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/blog/',
  algolia: undefined,
  localSearch: {"path":"/blog/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '【论文复现】Eyes Tell All_Irregular Pupil Shapes Reveal GAN-generated Faces',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/blog/images/profile.jpg" onerror="this.onerror=null;this.src='/blog/images/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/blog/archives/"><div class="headline">文章</div><div class="length-num">33</div></a><a href="/blog/tags/"><div class="headline">标签</div><div class="length-num">28</div></a><a href="/blog/categories/"><div class="headline">分类</div><div class="length-num">23</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/blog/"><i class="fa-fw fas fa-home"></i><span> 博客首页</span></a></div><div class="menus_item"><a class="site-page" href="/blog/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/blog/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/blog/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/blog/link/"><i class="fa-fw fa fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/blog/about/"><i class="fa-fw fas fa-camera"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="https://hozenghan.github.io"><i class="fa-fw fas fa-home"></i><span> 个人主页</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/blog/"><img class="site-icon" src="/blog/images/sun.png" alt="Logo"><span class="site-name">Hozenghan的博客</span></a><a class="nav-page-title" href="/blog/"><span class="site-name">【论文复现】Eyes Tell All_Irregular Pupil Shapes Reveal GAN-generated Faces</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/blog/"><i class="fa-fw fas fa-home"></i><span> 博客首页</span></a></div><div class="menus_item"><a class="site-page" href="/blog/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/blog/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/blog/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/blog/link/"><i class="fa-fw fa fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/blog/about/"><i class="fa-fw fas fa-camera"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="https://hozenghan.github.io"><i class="fa-fw fas fa-home"></i><span> 个人主页</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">【论文复现】Eyes Tell All_Irregular Pupil Shapes Reveal GAN-generated Faces</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-03-01T16:00:00.000Z" title="发表于 2025-03-02 00:00:00">2025-03-02</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-03-02T15:44:30.883Z" title="更新于 2025-03-02 23:44:30">2025-03-02</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/blog/categories/paper/">paper</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">4.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>18分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><div id="post-outdate-notice" data="{&quot;limitDay&quot;:365,&quot;messagePrev&quot;:&quot;It has been&quot;,&quot;messageNext&quot;:&quot;days since the last update, the content of the article may be outdated.&quot;,&quot;postUpdate&quot;:&quot;2025-03-02 23:44:30&quot;}" hidden></div><blockquote>
<p>最近在做信安赛（AI数字人实时检测），尝试实现真人生物特征检测，找到一篇2022年的文章，尝试复现</p>
</blockquote>
<ul>
<li><p>论文：Eyes Tell All: Irregular Pupil Shapes Reveal GAN-generated Faces</p>
</li>
<li><p>地址：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2109.00162">https://arxiv.org/abs/2109.00162</a></p>
</li>
</ul>
<blockquote>
<p>参考博客：</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/406470882">https://zhuanlan.zhihu.com/p/406470882</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/matt45m/article/details/139467321">https://blog.csdn.net/matt45m/article/details/139467321</a></p>
</blockquote>
<h2 id="文章概述"><a href="#文章概述" class="headerlink" title="文章概述"></a>文章概述</h2><blockquote>
<p>一句话总结全文：从两只眼睛中提取瞳孔并分析它们的形状，可以有效区分GAN生成的人脸和真实的人像照片。</p>
</blockquote>
<p>对于一个普遍意义上健全的人来说，瞳孔的形状是近乎圆形的。然而，在GAN生成的眼睛部分，可以观察到明显的伪影和不一致，如瞳孔的边界不是椭圆形的。如下图所示：</p>
<img src="https://raw.githubusercontent.com/Hozenghan/blogResources/master/paper_images/2109.00162v4_%E9%A1%B5%E9%9D%A2_1_%E5%9B%BE%E5%83%8F_0002.jpg" alt="2109.00162v4_页面_1_图像_0002" style="zoom: 50%;" />

<p>真实的眼睛（左），瞳孔为明显的圆形或椭圆形（黄色）；GAN生成的眼睛（右），瞳孔为不规则的形状（红色）。</p>
<p>这种现象普遍存在于GAN生成的人脸上，其中一个根本原因是，目前的GAN模型缺乏对人眼解剖学的理解，特别是瞳孔的几何形状。</p>
<h2 id="方法复现"><a href="#方法复现" class="headerlink" title="方法复现"></a>方法复现</h2><blockquote>
<p>总结该方法：作者利用模型对两只眼睛的瞳孔进行自动提取，并在之后评估这些瞳孔的形状是否为椭圆形。</p>
</blockquote>
<h4 id="1-瞳孔分割"><a href="#1-瞳孔分割" class="headerlink" title="1. 瞳孔分割"></a>1. 瞳孔分割</h4><p>首先通过人脸检测器来定位人脸，然后用提取器获得人脸的关键点（面部特征点）（如<code>(a)</code>图所示）。我们需要提取瞳孔的ROI区域，故需要根据关键点裁切眼部，对两只眼睛对应的区域进行适当裁剪后可以得到<code>(b)</code>图。</p>
<img src="https://raw.githubusercontent.com/Hozenghan/blogResources/master/paper_images/2109.00162v4_%E9%A1%B5%E9%9D%A2_3_%E5%9B%BE%E5%83%8F_0001.jpg" style="zoom: 50%;" />

<p>这一步通过多媒体机器学习模型应用框架mediapipe的<code>mediapipe face mesh</code>来实现，该工具可以<strong>实时检测和跟踪人脸的 3D 网格关键点</strong></p>
<blockquote>
<p>关于MediaPipe Face Mesh</p>
<p>MediaPipe Face Mesh是一种脸部几何解决方案，即使在移动设备上，也可以实时估计468个3D脸部界标（原文提到的dlib方法只能检测出68点）。它采用机器学习（ML）来推断3D表面几何形状，<u>只需要单个摄像机输入，而无需专用的深度传感器</u>。该解决方案利用轻量级的模型架构以及整个管线中的GPU加速，可提供对**<u><em>实时体验</em></u>**至关重要的实时性能</p>
</blockquote>
<blockquote>
<p><code>mediapipe face mesh</code>的github主页：<a target="_blank" rel="noopener" href="https://chuoling.github.io/mediapipe/solutions/face_mesh.html">https://chuoling.github.io/mediapipe/solutions/face_mesh.html</a></p>
<p>可参考博客推荐：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_42856191/article/details/139237456">https://blog.csdn.net/qq_42856191/article/details/139237456</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_72565814/article/details/141107377">https://blog.csdn.net/m0_72565814/article/details/141107377</a></li>
</ul>
</blockquote>
<h5 id="1-1-使用MediaPipe-Face-Mesh检测跟踪人脸网格关键点的示例代码一"><a href="#1-1-使用MediaPipe-Face-Mesh检测跟踪人脸网格关键点的示例代码一" class="headerlink" title="1.1.使用MediaPipe Face Mesh检测跟踪人脸网格关键点的示例代码一"></a>1.1.使用MediaPipe Face Mesh检测跟踪人脸网格关键点的示例代码一</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 调用本机摄像头实时检测</span></span><br><span class="line"><span class="keyword">import</span> mediapipe <span class="keyword">as</span> mp</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">mp_face_mesh = mp.solutions.face_mesh <span class="comment"># 定义了一个面部网格检测器</span></span><br><span class="line">face_mesh = mp_face_mesh.FaceMesh(static_image_mode=<span class="literal">False</span>,</span><br><span class="line">                                  max_num_faces=<span class="number">5</span>,      <span class="comment"># Maximum number of detected faces</span></span><br><span class="line">                                  refine_landmarks=<span class="literal">True</span>,    <span class="comment"># Whether to further refine the landmark coordinates around the eyes and lips</span></span><br><span class="line">                                  min_detection_confidence=<span class="number">0.5</span>,</span><br><span class="line">                                  min_tracking_confidence=<span class="number">0.5</span>) <span class="comment"># 定义用于初始化人脸网格模型的类</span></span><br><span class="line"></span><br><span class="line">mp_drawing = mp.solutions.drawing_utils</span><br><span class="line">mp_drawing_styles = mp.solutions.drawing_styles</span><br><span class="line"></span><br><span class="line">cap = cv2.VideoCapture(<span class="number">1</span>)</span><br><span class="line">pTime = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"></span><br><span class="line">    ret, img = cap.read()</span><br><span class="line">    height, width, channels = np.shape(img)</span><br><span class="line">    img_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class="line"></span><br><span class="line">    results = face_mesh.process(img_RGB)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 绘制部分</span></span><br><span class="line">    <span class="keyword">if</span> results.multi_face_landmarks:</span><br><span class="line">        <span class="keyword">for</span> face_landmarks <span class="keyword">in</span> results.multi_face_landmarks:</span><br><span class="line">            <span class="comment"># Draw a facial mesh</span></span><br><span class="line">            mp_drawing.draw_landmarks(image=img,</span><br><span class="line">                                      landmark_list=face_landmarks,</span><br><span class="line">                                      connections=mp_face_mesh.FACEMESH_TESSELATION,</span><br><span class="line">                                      landmark_drawing_spec=<span class="literal">None</span>,</span><br><span class="line">                                      connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())</span><br><span class="line">            <span class="comment"># Draw facial contours</span></span><br><span class="line">            mp_drawing.draw_landmarks(image=img,</span><br><span class="line">                                      landmark_list=face_landmarks,</span><br><span class="line">                                      connections=mp_face_mesh.FACEMESH_CONTOURS,</span><br><span class="line">                                      landmark_drawing_spec=<span class="literal">None</span>,</span><br><span class="line">                                      connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style())</span><br><span class="line">            <span class="comment"># Draw iris contours</span></span><br><span class="line">            mp_drawing.draw_landmarks(image=img,</span><br><span class="line">                                      landmark_list=face_landmarks,</span><br><span class="line">                                      connections=mp_face_mesh.FACEMESH_IRISES,</span><br><span class="line">                                      landmark_drawing_spec=<span class="literal">None</span>,</span><br><span class="line">                                      connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_iris_connections_style())</span><br><span class="line">            <span class="comment"># Draw facial keypoints</span></span><br><span class="line">            <span class="keyword">if</span> face_landmarks:</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">468</span>):</span><br><span class="line">                    pos_x = <span class="built_in">int</span>(face_landmarks.landmark[i].x * width)</span><br><span class="line">                    pos_y = <span class="built_in">int</span>(face_landmarks.landmark[i].y * height)</span><br><span class="line">                    cv2.circle(img, (pos_x, pos_y), <span class="number">3</span>, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    num_faces = <span class="built_in">len</span>(results.multi_face_landmarks) <span class="keyword">if</span> results.multi_face_landmarks <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Detected <span class="subst">&#123;num_faces&#125;</span> faces&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算并显示帧率</span></span><br><span class="line">    cTime = time.time()</span><br><span class="line">    fps = <span class="number">1</span> / (cTime - pTime)</span><br><span class="line">    pTime = cTime</span><br><span class="line">    cv2.putText(</span><br><span class="line">        img, <span class="string">f&quot;FPS: <span class="subst">&#123;<span class="built_in">int</span>(fps)&#125;</span>&quot;</span>, (<span class="number">20</span>, <span class="number">70</span>), cv2.FONT_HERSHEY_PLAIN, <span class="number">5</span>, (<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>), <span class="number">5</span></span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    cv2.imshow(<span class="string">&#x27;faces&#x27;</span>, img)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 按Q键退出</span></span><br><span class="line">    key = cv2.waitKey(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> key == <span class="built_in">ord</span>(<span class="string">&#x27;q&#x27;</span>):</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">cap.release()</span><br></pre></td></tr></table></figure>

<h5 id="1-2-使用MediaPipe-Face-Mesh检测跟踪人脸网格关键点的示例代码一"><a href="#1-2-使用MediaPipe-Face-Mesh检测跟踪人脸网格关键点的示例代码一" class="headerlink" title="1.2.使用MediaPipe Face Mesh检测跟踪人脸网格关键点的示例代码一"></a>1.2.使用MediaPipe Face Mesh检测跟踪人脸网格关键点的示例代码一</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 检测本地视频</span></span><br><span class="line"><span class="keyword">import</span> mediapipe <span class="keyword">as</span> mp</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">mp_face_mesh = mp.solutions.face_mesh  <span class="comment"># 定义面部网格检测器</span></span><br><span class="line">face_mesh = mp_face_mesh.FaceMesh(static_image_mode=<span class="literal">False</span>,</span><br><span class="line">                                  max_num_faces=<span class="number">5</span>,  <span class="comment"># 最大检测到的人脸数</span></span><br><span class="line">                                  refine_landmarks=<span class="literal">True</span>,  <span class="comment"># 是否进一步细化眼睛和嘴巴周围的标记点</span></span><br><span class="line">                                  min_detection_confidence=<span class="number">0.5</span>,</span><br><span class="line">                                  min_tracking_confidence=<span class="number">0.5</span>)  <span class="comment"># 定义面部网格模型的初始化参数</span></span><br><span class="line"></span><br><span class="line">mp_drawing = mp.solutions.drawing_utils</span><br><span class="line">mp_drawing_styles = mp.solutions.drawing_styles</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用本地视频文件路径来替换</span></span><br><span class="line">video_path = <span class="string">&quot;./video/2.mp4&quot;</span>  <span class="comment"># 替换为你的视频文件路径</span></span><br><span class="line">cap = cv2.VideoCapture(video_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查视频文件是否成功打开</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> cap.isOpened():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Error: Could not open video.&quot;</span>)</span><br><span class="line">    exit()</span><br><span class="line"></span><br><span class="line">pTime = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    ret, img = cap.read()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> ret:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Finished processing video or error occurred.&quot;</span>)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    height, width, channels = np.shape(img)</span><br><span class="line">    img_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class="line"></span><br><span class="line">    results = face_mesh.process(img_RGB)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 绘制部分</span></span><br><span class="line">    <span class="keyword">if</span> results.multi_face_landmarks:</span><br><span class="line">        <span class="keyword">for</span> face_landmarks <span class="keyword">in</span> results.multi_face_landmarks:</span><br><span class="line">            <span class="comment"># 绘制面部网格</span></span><br><span class="line">            mp_drawing.draw_landmarks(image=img,</span><br><span class="line">                                      landmark_list=face_landmarks,</span><br><span class="line">                                      connections=mp_face_mesh.FACEMESH_TESSELATION,</span><br><span class="line">                                      landmark_drawing_spec=<span class="literal">None</span>,</span><br><span class="line">                                      connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())</span><br><span class="line">            <span class="comment"># 绘制面部轮廓</span></span><br><span class="line">            mp_drawing.draw_landmarks(image=img,</span><br><span class="line">                                      landmark_list=face_landmarks,</span><br><span class="line">                                      connections=mp_face_mesh.FACEMESH_CONTOURS,</span><br><span class="line">                                      landmark_drawing_spec=<span class="literal">None</span>,</span><br><span class="line">                                      connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style())</span><br><span class="line">            <span class="comment"># 绘制虹膜轮廓</span></span><br><span class="line">            mp_drawing.draw_landmarks(image=img,</span><br><span class="line">                                      landmark_list=face_landmarks,</span><br><span class="line">                                      connections=mp_face_mesh.FACEMESH_IRISES,</span><br><span class="line">                                      landmark_drawing_spec=<span class="literal">None</span>,</span><br><span class="line">                                      connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_iris_connections_style())</span><br><span class="line">            <span class="comment"># 绘制面部关键点</span></span><br><span class="line">            <span class="keyword">if</span> face_landmarks:</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">468</span>):</span><br><span class="line">                    pos_x = <span class="built_in">int</span>(face_landmarks.landmark[i].x * width)</span><br><span class="line">                    pos_y = <span class="built_in">int</span>(face_landmarks.landmark[i].y * height)</span><br><span class="line">                    cv2.circle(img, (pos_x, pos_y), <span class="number">3</span>, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    num_faces = <span class="built_in">len</span>(results.multi_face_landmarks) <span class="keyword">if</span> results.multi_face_landmarks <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Detected <span class="subst">&#123;num_faces&#125;</span> faces&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算并显示帧率</span></span><br><span class="line">    cTime = time.time()</span><br><span class="line">    fps = <span class="number">1</span> / (cTime - pTime)</span><br><span class="line">    pTime = cTime</span><br><span class="line">    cv2.putText(</span><br><span class="line">        img, <span class="string">f&quot;FPS: <span class="subst">&#123;<span class="built_in">int</span>(fps)&#125;</span>&quot;</span>, (<span class="number">20</span>, <span class="number">70</span>), cv2.FONT_HERSHEY_PLAIN, <span class="number">5</span>, (<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>), <span class="number">5</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 显示处理后的图像</span></span><br><span class="line">    cv2.imshow(<span class="string">&#x27;faces&#x27;</span>, img)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 按 Q 键退出</span></span><br><span class="line">    key = cv2.waitKey(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> key == <span class="built_in">ord</span>(<span class="string">&#x27;q&#x27;</span>):</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 释放视频捕获对象</span></span><br><span class="line">cap.release()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

<h5 id="1-3-根据MediaPipe-Face-Mesh检测到的关键点裁切出眼部ROI区域"><a href="#1-3-根据MediaPipe-Face-Mesh检测到的关键点裁切出眼部ROI区域" class="headerlink" title="1.3.根据MediaPipe Face Mesh检测到的关键点裁切出眼部ROI区域"></a>1.3.根据MediaPipe Face Mesh检测到的关键点裁切出眼部ROI区域</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> mediapipe <span class="keyword">as</span> mp</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化MediaPipe面部网格模型</span></span><br><span class="line">mp_face_mesh = mp.solutions.face_mesh</span><br><span class="line">face_mesh = mp_face_mesh.FaceMesh(</span><br><span class="line">    static_image_mode=<span class="literal">False</span>,</span><br><span class="line">    max_num_faces=<span class="number">5</span>,</span><br><span class="line">    refine_landmarks=<span class="literal">True</span>,</span><br><span class="line">    min_detection_confidence=<span class="number">0.5</span>,</span><br><span class="line">    min_tracking_confidence=<span class="number">0.5</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义更精确的眼部关键点索引（参考MediaPipe官方文档）</span></span><br><span class="line">LEFT_EYE_INDICES = [<span class="number">33</span>, <span class="number">7</span>, <span class="number">163</span>, <span class="number">144</span>, <span class="number">145</span>, <span class="number">153</span>, <span class="number">154</span>, <span class="number">155</span>, <span class="number">133</span>, <span class="number">173</span>, <span class="number">157</span>, <span class="number">158</span>, <span class="number">159</span>, <span class="number">160</span>, <span class="number">161</span>, <span class="number">246</span>]  <span class="comment"># 左眼完整轮廓</span></span><br><span class="line">RIGHT_EYE_INDICES = [<span class="number">362</span>, <span class="number">382</span>, <span class="number">381</span>, <span class="number">380</span>, <span class="number">374</span>, <span class="number">373</span>, <span class="number">390</span>, <span class="number">249</span>, <span class="number">263</span>, <span class="number">466</span>, <span class="number">388</span>, <span class="number">387</span>, <span class="number">386</span>, <span class="number">385</span>, <span class="number">384</span>, <span class="number">398</span>]  <span class="comment"># 右眼完整轮廓</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 视频处理参数</span></span><br><span class="line">VIDEO_PATH = <span class="string">&quot;./video/4.mp4&quot;</span></span><br><span class="line">OUTPUT_DIR = <span class="string">&quot;./eye_images&quot;</span></span><br><span class="line">SAVE_INTERVAL = <span class="number">5</span>  <span class="comment"># 每5帧保存一次</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建输出目录（如果不存在）</span></span><br><span class="line">os.makedirs(OUTPUT_DIR, exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_eye_roi</span>(<span class="params">landmarks, eye_indices, frame_width, frame_height</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;获取眼部ROI区域并添加安全边界&quot;&quot;&quot;</span></span><br><span class="line">    points = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> eye_indices:</span><br><span class="line">        landmark = landmarks.landmark[i]</span><br><span class="line">        x = <span class="built_in">int</span>(landmark.x * frame_width)</span><br><span class="line">        y = <span class="built_in">int</span>(landmark.y * frame_height)</span><br><span class="line">        points.append((x, y))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算最小外接矩形</span></span><br><span class="line">    x, y, w, h = cv2.boundingRect(np.array(points))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 添加安全边界（20%的宽度/高度）</span></span><br><span class="line">    border = <span class="built_in">int</span>(<span class="built_in">max</span>(w, h) * <span class="number">0.2</span>)</span><br><span class="line">    x = <span class="built_in">max</span>(<span class="number">0</span>, x - border)</span><br><span class="line">    y = <span class="built_in">max</span>(<span class="number">0</span>, y - border)</span><br><span class="line">    w = <span class="built_in">min</span>(frame_width - x, w + <span class="number">2</span>*border)</span><br><span class="line">    h = <span class="built_in">min</span>(frame_height - y, h + <span class="number">2</span>*border)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> (x, y, w, h)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">crop_to_square</span>(<span class="params">image</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;将图像裁剪为1:1比例（正方形）&quot;&quot;&quot;</span></span><br><span class="line">    height, width = image.shape[:<span class="number">2</span>]</span><br><span class="line">    <span class="keyword">if</span> height == width:</span><br><span class="line">        <span class="keyword">return</span> image</span><br><span class="line">    <span class="comment"># 计算裁剪区域</span></span><br><span class="line">    size = <span class="built_in">min</span>(height, width)</span><br><span class="line">    start_x = (width - size) // <span class="number">2</span></span><br><span class="line">    start_y = (height - size) // <span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> image[start_y:start_y+size, start_x:start_x+size]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">safe_save_image</span>(<span class="params">image, path</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;安全保存图像，处理可能的异常&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">if</span> image.size == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;警告: 尝试保存空图像到 <span class="subst">&#123;path&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        cv2.imwrite(path, image)  <span class="comment"># 保存为PNG格式，PNG格式无需额外参数</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;保存图像错误 <span class="subst">&#123;path&#125;</span>: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化视频捕获</span></span><br><span class="line">cap = cv2.VideoCapture(VIDEO_PATH)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> cap.isOpened():</span><br><span class="line">    <span class="keyword">raise</span> FileNotFoundError(<span class="string">f&quot;无法打开视频文件 <span class="subst">&#123;VIDEO_PATH&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取视频信息</span></span><br><span class="line">fps = cap.get(cv2.CAP_PROP_FPS)</span><br><span class="line">frame_width = <span class="built_in">int</span>(cap.get(cv2.CAP_PROP_FRAME_WIDTH))</span><br><span class="line">frame_height = <span class="built_in">int</span>(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;视频信息: <span class="subst">&#123;frame_width&#125;</span>x<span class="subst">&#123;frame_height&#125;</span> @ <span class="subst">&#123;fps:<span class="number">.2</span>f&#125;</span> FPS&quot;</span>)</span><br><span class="line"></span><br><span class="line">pTime = <span class="number">0</span></span><br><span class="line">frame_count = <span class="number">0</span></span><br><span class="line">save_counter = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> ret:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 转换颜色空间</span></span><br><span class="line">    img_RGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)</span><br><span class="line">    results = face_mesh.process(img_RGB)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> results.multi_face_landmarks:</span><br><span class="line">        <span class="keyword">for</span> face_id, face_landmarks <span class="keyword">in</span> <span class="built_in">enumerate</span>(results.multi_face_landmarks):</span><br><span class="line">            <span class="comment"># 获取眼部ROI</span></span><br><span class="line">            left_roi = get_eye_roi(face_landmarks, LEFT_EYE_INDICES, frame_width, frame_height)</span><br><span class="line">            right_roi = get_eye_roi(face_landmarks, RIGHT_EYE_INDICES, frame_width, frame_height)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 裁剪眼部区域</span></span><br><span class="line">            left_eye = frame[left_roi[<span class="number">1</span>]:left_roi[<span class="number">1</span>]+left_roi[<span class="number">3</span>], left_roi[<span class="number">0</span>]:left_roi[<span class="number">0</span>]+left_roi[<span class="number">2</span>]]</span><br><span class="line">            right_eye = frame[right_roi[<span class="number">1</span>]:right_roi[<span class="number">1</span>]+right_roi[<span class="number">3</span>], right_roi[<span class="number">0</span>]:right_roi[<span class="number">0</span>]+right_roi[<span class="number">2</span>]]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 将眼部图像裁剪为1:1比例</span></span><br><span class="line">            left_eye_square = crop_to_square(left_eye)</span><br><span class="line">            right_eye_square = crop_to_square(right_eye)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 定期保存（每SAVE_INTERVAL帧）</span></span><br><span class="line">            <span class="keyword">if</span> frame_count % SAVE_INTERVAL == <span class="number">0</span>:</span><br><span class="line">                timestamp = <span class="built_in">int</span>(time.time() * <span class="number">1000</span>)</span><br><span class="line">                left_path = os.path.join(OUTPUT_DIR, <span class="string">f&quot;face_<span class="subst">&#123;face_id&#125;</span>_left_<span class="subst">&#123;frame_count&#125;</span>.png&quot;</span>)  <span class="comment"># 改为PNG格式</span></span><br><span class="line">                right_path = os.path.join(OUTPUT_DIR, <span class="string">f&quot;face_<span class="subst">&#123;face_id&#125;</span>_right_<span class="subst">&#123;frame_count&#125;</span>.png&quot;</span>)  <span class="comment"># 改为PNG格式</span></span><br><span class="line">                safe_save_image(left_eye_square, left_path)</span><br><span class="line">                safe_save_image(right_eye_square, right_path)</span><br><span class="line">                save_counter += <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 显示帧率</span></span><br><span class="line">    cTime = time.time()</span><br><span class="line">    fps = <span class="number">1</span> / (cTime - pTime)</span><br><span class="line">    pTime = cTime</span><br><span class="line">    cv2.putText(frame, <span class="string">f&quot;FPS: <span class="subst">&#123;<span class="built_in">int</span>(fps)&#125;</span>&quot;</span>, (<span class="number">20</span>, <span class="number">70</span>), cv2.FONT_HERSHEY_SIMPLEX, <span class="number">1</span>, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">2</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 显示处理结果</span></span><br><span class="line">    cv2.imshow(<span class="string">&#x27;Face Mesh Detection&#x27;</span>, frame)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 退出条件</span></span><br><span class="line">    <span class="keyword">if</span> cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span> == <span class="built_in">ord</span>(<span class="string">&#x27;q&#x27;</span>):</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    frame_count += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 释放资源</span></span><br><span class="line">cap.release()</span><br><span class="line">cv2.destroyAllWindows()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;处理完成，共保存 <span class="subst">&#123;save_counter&#125;</span> 张眼部图像&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>结果实例如下，</p>
<img src="https://raw.githubusercontent.com/Hozenghan/blogResources/master/paper_images/%E6%88%AA%E5%B1%8F2025-03-02%2022.58.35.png" style="zoom:50%;" />

<h4 id="2-边界检测"><a href="#2-边界检测" class="headerlink" title="2.边界检测"></a>2.边界检测</h4><p>获得眼部的ROI后，使用EyeCool提取瞳孔的掩码及其边界。</p>
<p>github源码：<a target="_blank" rel="noopener" href="https://github.com/neu-eyecool/NIR-ISL2021?tab=readme-ov-file">https://github.com/neu-eyecool/NIR-ISL2021?tab=readme-ov-file</a></p>
<blockquote>
<p>EyeCool是一个改进的基于U-Net的模型，可以同时对瞳孔和虹膜、内部和外部边界进行分割。其中EfﬁcientNet-B5被用作编码器，并在解码器中添加了一个边界注意块，以提高模型关注物体边界的能力。此外，Dice损失和MSE损失都被用来训练模型，其中Dice损失被用来评估分割部分，MSE被用来计算边界热图的回归损失。</p>
</blockquote>
<blockquote>
<p>关于EyeCool的一个比赛NIR-ISL-2021：<a target="_blank" rel="noopener" href="https://sites.google.com/view/nir-isl2021/home%E3%80%81https://github.com/xiamenwcy/NIR-ISL-2021">https://sites.google.com/view/nir-isl2021/home、https://github.com/xiamenwcy/NIR-ISL-2021</a></p>
</blockquote>
<blockquote>
<p>直接使用EyeCool的开源预训练模型以及<code>CASIA-Iris-Africa</code>数据集能够将论文中给出的人脸<code>(a)</code>的瞳孔掩码<code>(c)</code>检测出，但是更换人脸后效果不佳</p>
<p>开源预训练模型下载（提取码：x3zm）：<a target="_blank" rel="noopener" href="https://pan.baidu.com/share/init?surl=1zHhHryzhOhfJJ8NEPlv-g">https://pan.baidu.com/share/init?surl=1zHhHryzhOhfJJ8NEPlv-g</a></p>
</blockquote>
<h5 id="2-1-示例代码"><a href="#2-1-示例代码" class="headerlink" title="2.1.示例代码"></a>2.1.示例代码</h5><p>实例代码见github仓库<code>neu-eyecool</code>，测试模型文件位于<code>example/model_performance.py</code>中。结果如下</p>
<img src="https://raw.githubusercontent.com/Hozenghan/blogResources/master/paper_images/%E6%88%AA%E5%B1%8F2025-03-02%2023.07.56.png" style="zoom: 33%;" />

<p>另附命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python example/model_performance.py --dataset CASIA-Iris-Africa --ckpath yourPathToPTHFile</span><br><span class="line"></span><br><span class="line"><span class="comment"># 例如</span></span><br><span class="line">python example/model_performance.py --dataset CASIA-Iris-Africa --ckpath ./submission_1-checkpoints/afc-checkpoints</span><br></pre></td></tr></table></figure>

<h4 id="3-椭圆拟合瞳孔"><a href="#3-椭圆拟合瞳孔" class="headerlink" title="3.椭圆拟合瞳孔"></a>3.椭圆拟合瞳孔</h4><p>原文中提到椭圆拟合的瞳孔时利用基于最小平方的椭圆拟合方法可用于预测瞳孔掩码的外部边界，以估计椭圆拟合的瞳孔边界。</p>
<p>$u$为预测的瞳孔掩码的外边界上的点的坐标，利用最小二乘法找到一组参数$θ$，使数据点和椭圆之间的距离测量最小：</p>
<p>$$<br>F(u; \theta) &#x3D; \theta \cdot u &#x3D; ax^2 + bxy + cy^2 + dx + ey + f &#x3D; 0<br>$$<br>并通过最小化N个数据点上的代数距离平方之和来确定椭圆的大小：<br>$$<br>\mathcal{D}(\theta) &#x3D; \sum_{i&#x3D;1}^{N} F(u_i; \theta_i)^2, \ \text{subject to} \ |\theta|^2 &#x3D; 1 \quad (1)<br>$$<br>但是阅读EyeCool的源码后发现：执行<code>example/model_performance.py</code>代码时，EyeCool提取瞳孔的掩码后会调用<code>location/post_process.py</code>文件<strong>从预测的瞳孔&#x2F;虹膜掩码（mask）中提取椭圆边界</strong>，故最小平方拟合好像可以重新不用手写新的代码？</p>
<h4 id="4-估算瞳孔形状的不规则性"><a href="#4-估算瞳孔形状的不规则性" class="headerlink" title="4.估算瞳孔形状的不规则性"></a>4.估算瞳孔形状的不规则性</h4><p>本文作者使用BIoU来评估距离瞳孔外边界d像素范围内的瞳孔掩码像素。</p>
<blockquote>
<p>Boundary IoU（BIoU）可以用来对边界质量敏感的图像分割。相比于平等对待所有像素的Mask IoU，BIoU计算的是预测和基准真相之间的边界轮廓在一定距离内掩码像素的IoU。</p>
</blockquote>
<p>借用<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/406470882">知乎</a>的图，其中P表示预测的瞳孔掩码，F表示椭圆的瞳孔掩码，参数d是距离边界的距离，控制测量对边界的敏感性。</p>
<img src="https://raw.githubusercontent.com/Hozenghan/blogResources/master/paper_images/v2-9f9bd39faa478ae32959fc53811462b0_1440w.jpg" alt="img" style="zoom:33%;" />

<ul>
<li>左：预测的瞳孔掩码P和椭圆的瞳孔掩码F；</li>
<li>中：Pd和Fd是距离边界d以内的掩码像素（蓝色和黄色）；</li>
<li>右：预测的瞳孔掩码和椭圆修正的瞳孔掩码的距离参数d之间的边界IoU计算。</li>
</ul>
<p>此外，当把d放大到足以包括掩码内的所有像素时，BIoU就等于掩码IoU。为了使BIoU对边界质量更加敏感，可以减少参数d以忽略掩码内部像素。预测的瞳孔掩码和椭圆的瞳孔掩码之间的BIoU得分的范围是[0, 1]，<u><em><strong>较大的值表明瞳孔的边界与椭圆的形状更相似，那么人脸也更可能是真实的；否则就是用GAN模型生成的。</strong></em></u></p>
<h5 id="4-1-BIoU基础知识"><a href="#4-1-BIoU基础知识" class="headerlink" title="4.1.BIoU基础知识"></a>4.1.BIoU基础知识</h5><blockquote>
<p>BIoU原文：Boundary IoU: Improving Object-Centric Image Segmentation Evaluation</p>
<ul>
<li>论文：<a href="https://link.zhihu.com/?target=https://arxiv.org/pdf/2103.16562.pdf">https://arxiv.org/pdf/2103.16562.pdf</a></li>
<li>源码链接：<a target="_blank" rel="noopener" href="https://github.com/bowenc0221/b">https://github.com/bowenc0221/b</a></li>
</ul>
<p>参考中文博客：</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_50476352/article/details/116615065">https://blog.csdn.net/weixin_50476352/article/details/116615065</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/395498780">https://zhuanlan.zhihu.com/p/395498780</a></p>
<p>BIoU开源code：</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/HaoZiHuang/article/details/125613577">https://blog.csdn.net/HaoZiHuang/article/details/125613577</a></p>
</blockquote>
<h5 id="4-2-开源代码部分"><a href="#4-2-开源代码部分" class="headerlink" title="4.2.开源代码部分"></a>4.2.开源代码部分</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># General util function to get the boundary of a binary mask.</span></span><br><span class="line"><span class="comment"># 该函数用于获取二进制 mask 的边界</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mask_to_boundary</span>(<span class="params">mask, dilation_ratio=<span class="number">0.02</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Convert binary mask to boundary mask.</span></span><br><span class="line"><span class="string">    :param mask (numpy array, uint8): binary mask</span></span><br><span class="line"><span class="string">    :param dilation_ratio (float): ratio to calculate dilation = dilation_ratio * image_diagonal</span></span><br><span class="line"><span class="string">    :return: boundary mask (numpy array)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    h, w = mask.shape</span><br><span class="line">    img_diag = np.sqrt(h ** <span class="number">2</span> + w ** <span class="number">2</span>) <span class="comment"># 计算图像对角线长度</span></span><br><span class="line">    dilation = <span class="built_in">int</span>(<span class="built_in">round</span>(dilation_ratio * img_diag))</span><br><span class="line">    <span class="keyword">if</span> dilation &lt; <span class="number">1</span>:</span><br><span class="line">        dilation = <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">    mask = mask.astype(np.uint8)</span><br><span class="line">    <span class="comment"># Pad image so mask truncated by the image border is also considered as boundary.</span></span><br><span class="line">    new_mask = cv2.copyMakeBorder(mask, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, cv2.BORDER_CONSTANT, value=<span class="number">0</span>)</span><br><span class="line">    kernel = np.ones((<span class="number">3</span>, <span class="number">3</span>), dtype=np.uint8)</span><br><span class="line">    new_mask_erode = cv2.erode(new_mask, kernel, iterations=dilation)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 因为之前向四周填充了0, 故而这里不再需要四周</span></span><br><span class="line">    mask_erode = new_mask_erode[<span class="number">1</span> : h + <span class="number">1</span>, <span class="number">1</span> : w + <span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># G_d intersects G in the paper.</span></span><br><span class="line">    <span class="keyword">return</span> mask - mask_erode</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">boundary_iou</span>(<span class="params">gt, dt, dilation_ratio=<span class="number">0.005</span>, cls_num=<span class="number">2</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute boundary iou between two binary masks.</span></span><br><span class="line"><span class="string">    :param gt (numpy array, uint8): binary mask</span></span><br><span class="line"><span class="string">    :param dt (numpy array, uint8): binary mask</span></span><br><span class="line"><span class="string">    :param dilation_ratio (float): ratio to calculate dilation = dilation_ratio * image_diagonal</span></span><br><span class="line"><span class="string">    :return: boundary iou (float)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 注意 gt 和 dt 的 shape 不一样</span></span><br><span class="line">    <span class="comment"># gt = gt[0, 0]</span></span><br><span class="line">    <span class="comment"># dt = dt[0]</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 这里为了让 gt 和 dt 变为 (h, w) 而不是 (1, h, w) 或者 (1, 1, h, w)</span></span><br><span class="line">    </span><br><span class="line">	<span class="comment"># 注意这里的类别转换主要是为了后边计算边界</span></span><br><span class="line">    <span class="comment"># gt = gt.numpy().astype(np.uint8)</span></span><br><span class="line">    <span class="comment"># dt = dt.numpy().astype(np.uint8)</span></span><br><span class="line">    </span><br><span class="line">    gt = gt.astype(np.uint8)</span><br><span class="line">    dt = dt.astype(np.uint8)</span><br><span class="line">    </span><br><span class="line">    boundary_iou_list = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(cls_num):</span><br><span class="line">        </span><br><span class="line">        gt_i = (gt == i)</span><br><span class="line">        dt_i = (dt == i)</span><br><span class="line">        </span><br><span class="line">        gt_boundary = mask_to_boundary(gt_i, dilation_ratio)</span><br><span class="line">        dt_boundary = mask_to_boundary(dt_i, dilation_ratio)</span><br><span class="line">        intersection = ((gt_boundary * dt_boundary) &gt; <span class="number">0</span>).<span class="built_in">sum</span>()</span><br><span class="line">        union = ((gt_boundary + dt_boundary) &gt; <span class="number">0</span>).<span class="built_in">sum</span>()</span><br><span class="line">		<span class="keyword">if</span> union &lt; <span class="number">1</span>:</span><br><span class="line">            boundary_iou_list.append(<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        boundary_iou = intersection / union</span><br><span class="line">        boundary_iou_list.append( boundary_iou )</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> np.array(boundary_iou_list)</span><br></pre></td></tr></table></figure>

<h4 id="5-完整整合上述分布代码"><a href="#5-完整整合上述分布代码" class="headerlink" title="5.完整整合上述分布代码"></a>5.完整整合上述分布代码</h4><p>代码如下，</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">&#x27;./&#x27;</span>) <span class="comment"># change as you need</span></span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> nirislDataset</span><br><span class="line"><span class="keyword">from</span> models <span class="keyword">import</span> EfficientUNet</span><br><span class="line"><span class="keyword">from</span> location <span class="keyword">import</span> get_edge</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mask_to_boundary</span>(<span class="params">mask, dilation_ratio=<span class="number">0.02</span></span>):</span><br><span class="line">    mask = mask.astype(np.uint8)  <span class="comment"># 先把 mask 转换成 uint8 类型</span></span><br><span class="line">    h, w = mask.shape</span><br><span class="line">    img_diag = np.sqrt(h ** <span class="number">2</span> + w ** <span class="number">2</span>)</span><br><span class="line">    dilation = <span class="built_in">max</span>(<span class="built_in">int</span>(<span class="built_in">round</span>(dilation_ratio * img_diag)), <span class="number">1</span>)</span><br><span class="line">    new_mask = cv2.copyMakeBorder(mask, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, cv2.BORDER_CONSTANT, value=<span class="number">0</span>)</span><br><span class="line">    kernel = np.ones((<span class="number">3</span>, <span class="number">3</span>), dtype=np.uint8)</span><br><span class="line">    new_mask_erode = cv2.erode(new_mask, kernel, iterations=dilation)</span><br><span class="line">    <span class="keyword">return</span> mask - new_mask_erode[<span class="number">1</span>:h+<span class="number">1</span>, <span class="number">1</span>:w+<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">boundary_iou</span>(<span class="params">gt, dt, dilation_ratio=<span class="number">0.02</span></span>):</span><br><span class="line">    gt_boundary = mask_to_boundary(gt, dilation_ratio)</span><br><span class="line">    dt_boundary = mask_to_boundary(dt, dilation_ratio)</span><br><span class="line">    intersection = ((gt_boundary * dt_boundary) &gt; <span class="number">0</span>).<span class="built_in">sum</span>()</span><br><span class="line">    union = ((gt_boundary + dt_boundary) &gt; <span class="number">0</span>).<span class="built_in">sum</span>()</span><br><span class="line">    <span class="keyword">return</span> intersection / union</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_args</span>():</span><br><span class="line">    parser = argparse.ArgumentParser(description=<span class="string">&#x27;Test parameters&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--dataset&#x27;</span>, required=<span class="literal">True</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, dest=<span class="string">&#x27;dataset_name&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--ckpath&#x27;</span>, required=<span class="literal">True</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, dest=<span class="string">&#x27;checkpoints_path&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> parser.parse_args()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">check_mkdir</span>(<span class="params">dir_name</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(dir_name):</span><br><span class="line">        os.mkdir(dir_name)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">test_loader, net, save_dir</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Start testing...&#x27;</span>)</span><br><span class="line">    names, pupil_bious = [], []</span><br><span class="line">    </span><br><span class="line">    state_dict = torch.load(os.path.join(test_args[<span class="string">&#x27;checkpoints_path&#x27;</span>], <span class="string">&#x27;for_inner.pth&#x27;</span>), map_location=device)</span><br><span class="line">    state_dict[<span class="string">&quot;module.heatmap4.loc.0.weight&quot;</span>] = state_dict.pop(<span class="string">&#x27;module.loc4.loc.0.weight&#x27;</span>)</span><br><span class="line">    state_dict[<span class="string">&quot;module.heatmap3.loc.0.weight&quot;</span>] = state_dict.pop(<span class="string">&#x27;module.loc3.loc.0.weight&#x27;</span>)</span><br><span class="line">    state_dict[<span class="string">&quot;module.heatmap2.loc.0.weight&quot;</span>] = state_dict.pop(<span class="string">&#x27;module.loc2.loc.0.weight&#x27;</span>)</span><br><span class="line">    state_dict[<span class="string">&quot;module.heatmap4.loc.0.bias&quot;</span>] = state_dict.pop(<span class="string">&#x27;module.loc4.loc.0.bias&#x27;</span>)</span><br><span class="line">    state_dict[<span class="string">&quot;module.heatmap3.loc.0.bias&quot;</span>] = state_dict.pop(<span class="string">&#x27;module.loc3.loc.0.bias&#x27;</span>)</span><br><span class="line">    state_dict[<span class="string">&quot;module.heatmap2.loc.0.bias&quot;</span>] = state_dict.pop(<span class="string">&#x27;module.loc2.loc.0.bias&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    net.load_state_dict(state_dict)</span><br><span class="line">    net.<span class="built_in">eval</span>()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loader):</span><br><span class="line">        image_name, image = data[<span class="string">&#x27;image_name&#x27;</span>][<span class="number">0</span>], data[<span class="string">&#x27;image&#x27;</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Testing <span class="subst">&#123;i+<span class="number">1</span>&#125;</span>-th image: <span class="subst">&#123;image_name&#125;</span>&#x27;</span>)</span><br><span class="line">        image = Variable(image).to(device)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            outputs = net(image)</span><br><span class="line">        </span><br><span class="line">        pred_pupil_circle_mask, pred_pupil_egde, pupil_circles_param = get_edge(outputs[<span class="string">&#x27;pred_pupil_mask&#x27;</span>])</span><br><span class="line">        pred_pupil_mask = outputs[<span class="string">&#x27;pred_pupil_mask&#x27;</span>][<span class="number">0</span>,<span class="number">0</span>].cpu().numpy() &gt; <span class="number">0</span></span><br><span class="line">        gt_pupil_mask = pred_pupil_circle_mask[<span class="number">0</span>,<span class="number">0</span>].cpu().numpy() &gt; <span class="number">0</span></span><br><span class="line">        b_iou = boundary_iou(gt_pupil_mask, pred_pupil_mask)</span><br><span class="line">        pupil_bious.append(b_iou)</span><br><span class="line">        names.append(image_name)</span><br><span class="line">    </span><br><span class="line">    results_path = os.path.join(save_dir, <span class="string">&#x27;pupil_biou_results.xlsx&#x27;</span>)</span><br><span class="line">    pd.DataFrame(&#123;<span class="string">&#x27;name&#x27;</span>: names, <span class="string">&#x27;pupil_BIoU&#x27;</span>: pupil_bious&#125;).to_excel(results_path)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Test done!&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">test_args</span>):</span><br><span class="line">    net = EfficientUNet(num_classes=<span class="number">3</span>).to(device)</span><br><span class="line">    net = torch.nn.DataParallel(net)</span><br><span class="line">    test_dataset = nirislDataset(test_args[<span class="string">&#x27;dataset_name&#x27;</span>], mode=<span class="string">&#x27;test&#x27;</span>)</span><br><span class="line">    test_loader = DataLoader(test_dataset, batch_size=<span class="number">1</span>, drop_last=<span class="literal">False</span>)</span><br><span class="line">    </span><br><span class="line">    save_dir = os.path.join(<span class="string">&#x27;test-result&#x27;</span>, test_args[<span class="string">&#x27;dataset_name&#x27;</span>])</span><br><span class="line">    check_mkdir(save_dir)</span><br><span class="line">    test(test_loader, net, save_dir)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    args = get_args()</span><br><span class="line">    test_args = &#123;<span class="string">&#x27;dataset_name&#x27;</span>: args.dataset_name, <span class="string">&#x27;checkpoints_path&#x27;</span>: args.checkpoints_path&#125;</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    main(test_args)</span><br></pre></td></tr></table></figure>

<p>最后得到的BIoU值存在<code>test_result/pupil_biou_results.xlsx</code>内。</p>
<h2 id="优化方向"><a href="#优化方向" class="headerlink" title="优化方向"></a>优化方向</h2><p>该论文的方法和已有开源模型好像只在论文给出的图片中效果较好，在自己尝试的图片和视频中效果欠佳，需要优化。</p>
<ul>
<li>重新训练EyeCool模型？（😭好像不现实）</li>
<li>再找别的真人生物特征检测开源代码</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://hozenghan.github.io/blog">Hozenghan</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://hozenghan.github.io/blog/2025/03/02/paper/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91Eyes%20Tell%20All_Irregular%20Pupil%20Shapes%20Reveal%20GAN-generated%20Faces/">http://hozenghan.github.io/blog/2025/03/02/paper/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91Eyes%20Tell%20All_Irregular%20Pupil%20Shapes%20Reveal%20GAN-generated%20Faces/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://hozenghan.github.io/blog" target="_blank">Hozenghan的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/blog/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/">网络安全</a><a class="post-meta__tags" href="/blog/tags/scu/">scu</a><a class="post-meta__tags" href="/blog/tags/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/">论文复现</a><a class="post-meta__tags" href="/blog/tags/paper/">paper</a><a class="post-meta__tags" href="/blog/tags/GAN/">GAN</a></div><div class="post-share"><div class="social-share" data-image="/blog/coverImages/paper-1.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/blog/2025/02/22/%E5%85%B6%E4%BB%96/recraft/" title="Recraft"><img class="cover" src="/blog/coverImages/recraft.jpg" onerror="onerror=null;src='/blog/images/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Recraft</div></div><div class="info-2"><div class="info-item-1">www.recraft.ai</div></div></div></a><a class="pagination-related" href="/blog/2025/03/03/cad:cg/Bezier%E6%9B%B2%E9%9D%A2/" title="【CAD/CG笔记】关于Bezier曲面"><img class="cover" src="/blog/coverImages/cg&amp;cad_bezier-surface.jpg" onerror="onerror=null;src='/blog/images/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">【CAD/CG笔记】关于Bezier曲面</div></div><div class="info-2"><div class="info-item-1">总结Bezier曲面相关知识</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/blog/2025/01/16/scu/2024-2025%E5%AD%A6%E5%B9%B4_%E7%A7%8B/%E7%BD%91%E7%BB%9C%E6%94%BB%E9%98%B2%E6%9C%9F%E6%9C%AB%E9%87%8D%E7%82%B9/" title="【SCU期末】网络攻防技术期末重点"><img class="cover" src="/blog/coverImages/scu_24-25_gf-2.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-01-16</div><div class="info-item-2">【SCU期末】网络攻防技术期末重点</div></div><div class="info-2"><div class="info-item-1">记录了scu_ccs期末专业课的重点笔记，对scu_ccs有较大帮助</div></div></div></a><a class="pagination-related" href="/blog/2025/01/16/scu/2024-2025%E5%AD%A6%E5%B9%B4_%E7%A7%8B/%E7%BD%91%E7%BB%9C%E6%94%BB%E9%98%B2%E5%AE%9E%E9%AA%8C%E6%80%BB%E7%BB%93/" title="【SCU期末】网络攻防技术实验总结"><img class="cover" src="/blog/coverImages/scu_24-25_gf-1.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-01-16</div><div class="info-item-2">【SCU期末】网络攻防技术实验总结</div></div><div class="info-2"><div class="info-item-1">记录了scu_ccs期末专业课的重点笔记，对scu_ccs有较大帮助</div></div></div></a><a class="pagination-related" href="/blog/2025/01/16/scu/2024-2025%E5%AD%A6%E5%B9%B4_%E7%A7%8B/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E6%8A%80%E6%9C%AF_final/" title="【SCU期末】网络空间安全技术期末整理"><img class="cover" src="/blog/coverImages/scu_24-25_js.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-01-16</div><div class="info-item-2">【SCU期末】网络空间安全技术期末整理</div></div><div class="info-2"><div class="info-item-1">记录了scu_ccs期末专业课的重点笔记，对scu_ccs有较大帮助</div></div></div></a><a class="pagination-related" href="/blog/2024/06/30/scu/2023-2024%E5%AD%A6%E5%B9%B4_%E6%98%A5/%E5%BA%94%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6%E6%8F%90%E7%BA%B2/" title="【SCU期末】scu应用密码学期末提纲"><img class="cover" src="/blog/coverImages/scu_23-24_yymmx.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-06-30</div><div class="info-item-2">【SCU期末】scu应用密码学期末提纲</div></div><div class="info-2"><div class="info-item-1">仅记录了任课老师课堂提示的重点提纲，对scu_ccs有较大帮助</div></div></div></a><a class="pagination-related" href="/blog/2024/06/30/scu/2023-2024%E5%AD%A6%E5%B9%B4_%E6%98%A5/os%E7%AE%80%E7%AD%94%E9%A2%98%E6%8F%90%E7%BA%B2/" title="【SCU期末】scu操作系统期末简答题提纲"><img class="cover" src="/blog/coverImages/scu_23-24_os-1.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-06-30</div><div class="info-item-2">【SCU期末】scu操作系统期末简答题提纲</div></div><div class="info-2"><div class="info-item-1">仅记录了任课老师课堂提示的重点提纲，具体细化梳理见“scu操作系统期末简答题提纲”，对scu_ccs的os有较大帮助</div></div></div></a><a class="pagination-related" href="/blog/2024/06/30/scu/2023-2024%E5%AD%A6%E5%B9%B4_%E6%98%A5/os%E7%AE%80%E7%AD%94%E9%A2%98%E6%95%B4%E7%90%86/" title="【SCU期末】scu操作系统期末简答题整理"><img class="cover" src="/blog/coverImages/scu_23-24_os-2.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-06-30</div><div class="info-item-2">【SCU期末】scu操作系统期末简答题整理</div></div><div class="info-2"><div class="info-item-1">重点梳理，对scu_ccs的os有较大帮助</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/blog/images/profile.jpg" onerror="this.onerror=null;this.src='/blog/images/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Hozenghan</div><div class="author-info-description">📷   🖥️   📖  💤   🛵</div><div class="site-data"><a href="/blog/archives/"><div class="headline">文章</div><div class="length-num">33</div></a><a href="/blog/tags/"><div class="headline">标签</div><div class="length-num">28</div></a><a href="/blog/categories/"><div class="headline">分类</div><div class="length-num">23</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Hozenghan"><i class="fab fa-github"></i><span>Follow Me!</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/Hozenghan" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="/blog/QQ" target="_blank" title=""><i class="fab fa-qq"></i></a><a class="social-icon" href="mailto:wuzhenghannnnnn@163.com" target="_blank" title="Email"><i class="fas fa-envelope-open-text"></i></a><a class="social-icon" href="https://hozenghan.github.io" target="_blank" title=""><i class="fas fa-home"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">无限进步！建议挂上梯子，不然有些图片可能会加载不出来。天天开心哦🥰</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%87%E7%AB%A0%E6%A6%82%E8%BF%B0"><span class="toc-number">1.</span> <span class="toc-text">文章概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E6%B3%95%E5%A4%8D%E7%8E%B0"><span class="toc-number">2.</span> <span class="toc-text">方法复现</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E7%9E%B3%E5%AD%94%E5%88%86%E5%89%B2"><span class="toc-number">2.0.1.</span> <span class="toc-text">1. 瞳孔分割</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-1-%E4%BD%BF%E7%94%A8MediaPipe-Face-Mesh%E6%A3%80%E6%B5%8B%E8%B7%9F%E8%B8%AA%E4%BA%BA%E8%84%B8%E7%BD%91%E6%A0%BC%E5%85%B3%E9%94%AE%E7%82%B9%E7%9A%84%E7%A4%BA%E4%BE%8B%E4%BB%A3%E7%A0%81%E4%B8%80"><span class="toc-number">2.0.1.1.</span> <span class="toc-text">1.1.使用MediaPipe Face Mesh检测跟踪人脸网格关键点的示例代码一</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-2-%E4%BD%BF%E7%94%A8MediaPipe-Face-Mesh%E6%A3%80%E6%B5%8B%E8%B7%9F%E8%B8%AA%E4%BA%BA%E8%84%B8%E7%BD%91%E6%A0%BC%E5%85%B3%E9%94%AE%E7%82%B9%E7%9A%84%E7%A4%BA%E4%BE%8B%E4%BB%A3%E7%A0%81%E4%B8%80"><span class="toc-number">2.0.1.2.</span> <span class="toc-text">1.2.使用MediaPipe Face Mesh检测跟踪人脸网格关键点的示例代码一</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-3-%E6%A0%B9%E6%8D%AEMediaPipe-Face-Mesh%E6%A3%80%E6%B5%8B%E5%88%B0%E7%9A%84%E5%85%B3%E9%94%AE%E7%82%B9%E8%A3%81%E5%88%87%E5%87%BA%E7%9C%BC%E9%83%A8ROI%E5%8C%BA%E5%9F%9F"><span class="toc-number">2.0.1.3.</span> <span class="toc-text">1.3.根据MediaPipe Face Mesh检测到的关键点裁切出眼部ROI区域</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E8%BE%B9%E7%95%8C%E6%A3%80%E6%B5%8B"><span class="toc-number">2.0.2.</span> <span class="toc-text">2.边界检测</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-1-%E7%A4%BA%E4%BE%8B%E4%BB%A3%E7%A0%81"><span class="toc-number">2.0.2.1.</span> <span class="toc-text">2.1.示例代码</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E6%A4%AD%E5%9C%86%E6%8B%9F%E5%90%88%E7%9E%B3%E5%AD%94"><span class="toc-number">2.0.3.</span> <span class="toc-text">3.椭圆拟合瞳孔</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-%E4%BC%B0%E7%AE%97%E7%9E%B3%E5%AD%94%E5%BD%A2%E7%8A%B6%E7%9A%84%E4%B8%8D%E8%A7%84%E5%88%99%E6%80%A7"><span class="toc-number">2.0.4.</span> <span class="toc-text">4.估算瞳孔形状的不规则性</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#4-1-BIoU%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86"><span class="toc-number">2.0.4.1.</span> <span class="toc-text">4.1.BIoU基础知识</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-2-%E5%BC%80%E6%BA%90%E4%BB%A3%E7%A0%81%E9%83%A8%E5%88%86"><span class="toc-number">2.0.4.2.</span> <span class="toc-text">4.2.开源代码部分</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-%E5%AE%8C%E6%95%B4%E6%95%B4%E5%90%88%E4%B8%8A%E8%BF%B0%E5%88%86%E5%B8%83%E4%BB%A3%E7%A0%81"><span class="toc-number">2.0.5.</span> <span class="toc-text">5.完整整合上述分布代码</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E6%96%B9%E5%90%91"><span class="toc-number">3.</span> <span class="toc-text">优化方向</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/blog/2025/03/17/coding/matlab/1-matlab/" title="matlab"><img src="/blog/coverImages/code_matlab.jpg" onerror="this.onerror=null;this.src='/blog/images/404.jpg'" alt="matlab"/></a><div class="content"><a class="title" href="/blog/2025/03/17/coding/matlab/1-matlab/" title="matlab">matlab</a><time datetime="2025-03-17T15:59:48.000Z" title="发表于 2025-03-17 23:59:48">2025-03-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/2025/03/16/cad:cg/B-Spline/" title="【CAD/CG笔记】关于B-Spline"><img src="/blog/coverImages/cg&amp;cad_b-spline.jpg" onerror="this.onerror=null;this.src='/blog/images/404.jpg'" alt="【CAD/CG笔记】关于B-Spline"/></a><div class="content"><a class="title" href="/blog/2025/03/16/cad:cg/B-Spline/" title="【CAD/CG笔记】关于B-Spline">【CAD/CG笔记】关于B-Spline</a><time datetime="2025-03-16T15:59:50.000Z" title="发表于 2025-03-16 23:59:50">2025-03-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/2025/03/05/MachineLearning/%E3%80%90ML%E7%AC%94%E8%AE%B0%E3%80%91%E6%95%B0%E6%8D%AE%E9%9B%86%E6%B8%85%E6%B4%97/" title="【ML笔记】数据集清洗"><img src="/blog/coverImages/ml-3.jpg" onerror="this.onerror=null;this.src='/blog/images/404.jpg'" alt="【ML笔记】数据集清洗"/></a><div class="content"><a class="title" href="/blog/2025/03/05/MachineLearning/%E3%80%90ML%E7%AC%94%E8%AE%B0%E3%80%91%E6%95%B0%E6%8D%AE%E9%9B%86%E6%B8%85%E6%B4%97/" title="【ML笔记】数据集清洗">【ML笔记】数据集清洗</a><time datetime="2025-03-05T15:59:50.000Z" title="发表于 2025-03-05 23:59:50">2025-03-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/2025/03/03/cad:cg/Bezier%E6%9B%B2%E9%9D%A2/" title="【CAD/CG笔记】关于Bezier曲面"><img src="/blog/coverImages/cg&amp;cad_bezier-surface.jpg" onerror="this.onerror=null;this.src='/blog/images/404.jpg'" alt="【CAD/CG笔记】关于Bezier曲面"/></a><div class="content"><a class="title" href="/blog/2025/03/03/cad:cg/Bezier%E6%9B%B2%E9%9D%A2/" title="【CAD/CG笔记】关于Bezier曲面">【CAD/CG笔记】关于Bezier曲面</a><time datetime="2025-03-03T15:59:50.000Z" title="发表于 2025-03-03 23:59:50">2025-03-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/2025/03/02/paper/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91Eyes%20Tell%20All_Irregular%20Pupil%20Shapes%20Reveal%20GAN-generated%20Faces/" title="【论文复现】Eyes Tell All_Irregular Pupil Shapes Reveal GAN-generated Faces"><img src="/blog/coverImages/paper-1.jpg" onerror="this.onerror=null;this.src='/blog/images/404.jpg'" alt="【论文复现】Eyes Tell All_Irregular Pupil Shapes Reveal GAN-generated Faces"/></a><div class="content"><a class="title" href="/blog/2025/03/02/paper/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91Eyes%20Tell%20All_Irregular%20Pupil%20Shapes%20Reveal%20GAN-generated%20Faces/" title="【论文复现】Eyes Tell All_Irregular Pupil Shapes Reveal GAN-generated Faces">【论文复现】Eyes Tell All_Irregular Pupil Shapes Reveal GAN-generated Faces</a><time datetime="2025-03-01T16:00:00.000Z" title="发表于 2025-03-02 00:00:00">2025-03-02</time></div></div></div></div></div></div></main><footer id="footer" style="background: linear-gradient(20deg, #003366, #0066cc, #3399ff, #66ccff);"><div id="footer-wrap"><div class="copyright">&copy;2024 - 2025 By Hozenghan</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hey you, welcome to my blog!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/blog/js/utils.js"></script><script src="/blog/js/main.js"></script><script src="/blog/js/tw_cn.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/blog/js/search/local-search.js"></script></div></div></body></html>